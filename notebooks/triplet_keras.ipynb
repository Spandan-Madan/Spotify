{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations in Keras using triplet loss\n",
    "Along the lines of BPR [1]. \n",
    "\n",
    "[1] Rendle, Steffen, et al. \"BPR: Bayesian personalized ranking from implicit feedback.\" Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. AUAI Press, 2009.\n",
    "\n",
    "This is implemented (more efficiently) in LightFM (https://github.com/lyst/lightfm). See the MovieLens example (https://github.com/lyst/lightfm/blob/master/examples/movielens/example.ipynb) for results comparable to this notebook.\n",
    "\n",
    "## Set up the architecture\n",
    "A simple dense layer for both users and items: this is exactly equivalent to latent factor matrix when multiplied by binary user and item indices. There are three inputs: users, positive items, and negative items. In the triplet objective we try to make the positive item rank higher than the negative item for that user.\n",
    "\n",
    "Because we want just one single embedding for the items, we use shared weights for the positive and negative item inputs (a siamese architecture).\n",
    "\n",
    "This is all very simple but could be made arbitrarily complex, with more layers, conv layers and so on. I expect we'll be seeing a lot of papers doing just that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Triplet loss network example for recommenders\n",
    "\"\"\"\n",
    "from keras.models import load_model\n",
    "from __future__ import print_function\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense,Dropout\n",
    "\n",
    "# import data\n",
    "# import metrics\n",
    "\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "\n",
    "def bpr_triplet_loss(X):\n",
    "    first_item_latent, second_item_latent, random_item_latent = X\n",
    "\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(first_item_latent * second_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(first_item_latent * random_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def standard_triplet_loss(X):\n",
    "    first_item_latent, random_item_latent, second_item_latent = X\n",
    "    \n",
    "    term1 = K.pow((first_item_latent - second_item_latent),2)\n",
    "    term1_nrom = K.l2_normalize(term1)\n",
    "    sum1 = K.sum(term1_norm)\n",
    "    term2 = K.pow((first_item_latent - random_item_latent),2)\n",
    "    term2_nrom = K.l2_normalize(term2)\n",
    "    sum2 = K.sum(term2_norm)\n",
    "    loss = K.maximum(sum1 - sum2 + 0.2,0)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and transform data\n",
    "We're going to load the Movielens 100k dataset and create triplets of (user, known positive item, randomly sampled negative item).\n",
    "\n",
    "The success metric is AUC: in this case, the probability that a randomly chosen known positive item from the test set is ranked higher for a given user than a ranomly chosen negative item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading songs and converting into one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/spandanmadan/Desktop/Spotify/Spotify/notebooks'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics = []\n",
    "for pid in range(2355):\n",
    "    f = open('../data/pooling/scraped_lyrics_%s.p'%pid,'rb')\n",
    "    lyrics_list = pickle.load(f)\n",
    "    f.close()\n",
    "    all_lyrics += lyrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "text = [' '.join(words) for words in all_lyrics]\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer(max_df = 0.9,min_df = 0.01)\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open()\n",
    "vectorizer = pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uris = []\n",
    "pid_to_uris = {}\n",
    "for pid in range(2355):\n",
    "    f = open('../data/pooling/scraped_lyrics_uris_%s.p'%pid,'rb')\n",
    "    uris_list = pickle.load(f)\n",
    "    f.close()\n",
    "    pid_to_uris[pid] = uris_list\n",
    "    all_uris += uris_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging to see sizes etc are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = vectorizer.transform(all_lyrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n"
     ]
    }
   ],
   "source": [
    "uri_to_lyrics = {}\n",
    "for i in range(len(all_uris)):\n",
    "    if i %1000 == 0:\n",
    "        print(i)\n",
    "    uri = all_uris[i]\n",
    "    lyrics = all_lyrics[i]\n",
    "    if lyrics == []:\n",
    "        lyrics = [' ']\n",
    "#     vector = vectorizer.transform(lyrics)\n",
    "#     nparray = vector.toarray()\n",
    "    uri_to_lyrics[uri] = [' '.join(lyrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('uri_to_lyrics.p','wb')\n",
    "# pickle.dump(uri_to_lyrics,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = vectorizer.transform(uri_to_lyrics['0UaMYEvWZi0ZqiDOoHU3YI']).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uris = list(set(uri_to_lyrics.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1419)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(uri_to_lyrics['0UaMYEvWZi0ZqiDOoHU3YI']).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 300\n",
    "NUM_EPOCHS = 5000\n",
    "BATCH_SIZE = 5\n",
    "timesteps = 11\n",
    "features = 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(BATCH_SIZE,vector_size,unique_uris):\n",
    "    found = 0\n",
    "    while not found:\n",
    "        pid = random.randint(0,2354)\n",
    "        playlist_uris = pid_to_uris[pid]\n",
    "        \n",
    "        first_part = playlist_uris[:int(len(playlist_uris)*0.75)]\n",
    "        second_part = playlist_uris[int(len(playlist_uris)*0.75):]\n",
    "        random_part = [i for i in unique_uris if i not in playlist_uris]\n",
    "        \n",
    "        try:\n",
    "            indices1 = random.sample(range(1,len(first_part)),BATCH_SIZE)\n",
    "            indices2 = random.sample(range(1,len(second_part)),BATCH_SIZE)\n",
    "            indices3 = random.sample(range(1,len(random_part)),BATCH_SIZE)\n",
    "            found =1 \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    data_first_song = np.zeros((BATCH_SIZE,vector_size))\n",
    "    data_second_song = np.zeros((BATCH_SIZE,vector_size))\n",
    "    data_random_song = np.zeros((BATCH_SIZE,vector_size))\n",
    "    \n",
    "    first_uris = []\n",
    "    second_uris = []\n",
    "    random_uris = []\n",
    "    \n",
    "    for i in range(len(indices1)):\n",
    "        data_first_song[i] = vectorizer.transform(uri_to_lyrics[first_part[indices1[i]]]).toarray()\n",
    "        data_second_song[i] = vectorizer.transform(uri_to_lyrics[second_part[indices2[i]]]).toarray()\n",
    "        data_random_song[i] = vectorizer.transform(uri_to_lyrics[random_part[indices3[i]]]).toarray()\n",
    "        \n",
    "        first_uris.append(first_part[indices1[i]])\n",
    "        second_uris.append(second_part[indices2[i]])\n",
    "        random_uris.append(random_part[indices3[i]])\n",
    "        \n",
    "    uris = (first_uris,second_uris,random_uris)\n",
    "    reshaped_1 = data_first_song.reshape((BATCH_SIZE,timesteps,-1))\n",
    "    reshaped_2 = data_second_song.reshape((BATCH_SIZE,timesteps,-1))\n",
    "    reshaped_random = data_random_song.reshape((BATCH_SIZE,timesteps,-1))\n",
    "    return reshaped_1, reshaped_2, reshaped_random,uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = get_train_batch(BATCH_SIZE,vector_size,unique_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visible = Input(shape=(100,1))\n",
    "# # feature extraction\n",
    "# extract = LSTM(10, return_sequences=True)(visible)\n",
    "# # classification output\n",
    "# class11 = LSTM(10)(extract)\n",
    "# class12 = Dense(10, activation='relu')(class11)\n",
    "# output1 = Dense(1, activation='sigmoid')(class12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_merge(X):\n",
    "    first,second,random = X\n",
    "    good = K.pow((first-second),2)\n",
    "    bad = K.pow((first-random),2)\n",
    "    \n",
    "    K.sum(good,bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/anaconda/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"lo...)`\n"
     ]
    }
   ],
   "source": [
    "# positive_item_input = Input((1, ), name='positive_item_input')\n",
    "# negative_item_input = Input((1, ), name='negative_item_input')\n",
    "\n",
    "# # Shared embedding layer for positive and negative items\n",
    "# item_embedding_layer = Embedding(\n",
    "#     10, 10, name='item_embedding', input_length=1)\n",
    "\n",
    "# user_input = Input((1, ), name='user_input')\n",
    "\n",
    "# positive_item_embedding = Flatten()(item_embedding_layer(\n",
    "#     positive_item_input))\n",
    "# negative_item_embedding = Flatten()(item_embedding_layer(\n",
    "#     negative_item_input))\n",
    "# user_embedding = Flatten()(Embedding(\n",
    "#     10, 10, name='user_embedding', input_length=1)(\n",
    "#         user_input))\n",
    "\n",
    "# loss = merge(\n",
    "#     [positive_item_embedding, negative_item_embedding, user_embedding],\n",
    "#     mode=bpr_triplet_loss,\n",
    "#     name='loss',\n",
    "#     output_shape=(1, ))\n",
    "\n",
    "# model__ = Model(\n",
    "#     input=[positive_item_input, negative_item_input, user_input],\n",
    "#     output=loss)\n",
    "# model__.compile(loss=identity_loss, optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_LSTM_layer = LSTM(700,return_sequences=True)\n",
    "shared_dropout_layer = Dropout(0.5)\n",
    "shared_LSTM_layer2 = LSTM(500,return_sequences=True)\n",
    "shared_dense_layer = Dense(1000,activation='relu')\n",
    "shared_dense_layer_2 = Dense(300, activation='relu')\n",
    "shared_dropout_layer_2 = Dropout(0.5)\n",
    "shared_flatten = Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared_dense_layer_2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/anaconda/lib/python3.6/site-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "# first input\n",
    "visible_1 = Input(shape=(timesteps,features))\n",
    "extract_1 = shared_LSTM_layer(visible_1)\n",
    "dropped_1 = shared_dropout_layer(extract_1)\n",
    "extract_2 = shared_LSTM_layer2(dropped_1)\n",
    "dropped_2 = shared_dropout_layer_2(extract_2)\n",
    "flatten_1 = shared_flatten(dropped_2)\n",
    "dense_1 = shared_dense_layer(flatten_1)\n",
    "dense_2 = shared_dense_layer_2(dense_1)\n",
    "\n",
    "# Second input\n",
    "visible_1_2 = Input(shape=(timesteps,features))\n",
    "extract_1_2 = shared_LSTM_layer(visible_1_2)\n",
    "dropped_1_2 = shared_dropout_layer(extract_1_2)\n",
    "extract_2_2 = shared_LSTM_layer2(dropped_1_2)\n",
    "dropped_2_2 = shared_dropout_layer_2(extract_2_2)\n",
    "flatten_1_2 = shared_flatten(dropped_2_2)\n",
    "dense_1_2 = shared_dense_layer(flatten_1_2)\n",
    "dense_2_2 = shared_dense_layer_2(dense_1_2)\n",
    "\n",
    "# Third input \n",
    "visible_1_3 = Input(shape=(timesteps,features))\n",
    "extract_1_3 = shared_LSTM_layer(visible_1_3)\n",
    "dropped_1_3 = shared_dropout_layer(extract_1_3)\n",
    "extract_2_3 = shared_LSTM_layer2(dropped_1_3)\n",
    "dropped_2_3 = shared_dropout_layer_2(extract_2_3)\n",
    "flatten_1_3 = shared_flatten(dropped_2_3)\n",
    "dense_1_3 = shared_dense_layer(flatten_1_3)\n",
    "dense_2_3 = shared_dense_layer_2(dense_1_3)\n",
    "\n",
    "output = merge([dense_2,dense_2_2,dense_2_3],mode=standard_triplet_loss,output_shape=(1,))\n",
    "model = Model(inputs=[visible_1,visible_1_2,visible_1_3], outputs=output)\n",
    "plot_model(model,to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 11, 129)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 11, 129)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 11, 129)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 11, 700)      2324000     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 11, 700)      0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "                                                                 lstm_3[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 11, 500)      2402000     dropout_3[0][0]                  \n",
      "                                                                 dropout_3[1][0]                  \n",
      "                                                                 dropout_3[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 11, 500)      0           lstm_4[0][0]                     \n",
      "                                                                 lstm_4[1][0]                     \n",
      "                                                                 lstm_4[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 5500)         0           dropout_4[0][0]                  \n",
      "                                                                 dropout_4[1][0]                  \n",
      "                                                                 dropout_4[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1000)         5501000     flatten_5[0][0]                  \n",
      "                                                                 flatten_5[1][0]                  \n",
      "                                                                 flatten_5[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 300)          300300      dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "                                                                 dense_3[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 1)            0           dense_4[0][0]                    \n",
      "                                                                 dense_4[1][0]                    \n",
      "                                                                 dense_4[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,527,300\n",
      "Trainable params: 10,527,300\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared_LSTM_layer = LSTM(700,return_sequences=True)\n",
    "# shared_dropout_layer = Dropout(0.5)\n",
    "# shared_LSTM_layer2 = LSTM(500,return_sequences=True)\n",
    "# shared_dense_layer = Dense(500,activation='relu')\n",
    "# shared_dense_layer_2 = Dense(300, activation='relu')\n",
    "\n",
    "# # first input\n",
    "# visible_1 = Input(shape=(timesteps,features))\n",
    "# extract_1 = shared_LSTM_layer(visible_1)\n",
    "# dropped_1 = shared_dropout_layer(extract_1)\n",
    "# extract_2 = shared_LSTM_layer2(dropped_1)\n",
    "# dropped_2 = shared_dropout_layer(extract_2)\n",
    "# dense_1 = shared_dense_layer(dropped_2)\n",
    "# dense_2 = shared_dense_layer_2(dense_1)\n",
    "\n",
    "# # Second input\n",
    "# visible_1_2 = Input(shape=(timesteps,features))\n",
    "# extract_1_2 = shared_LSTM_layer(visible_1_2)\n",
    "# dropped_1_2 = shared_dropout_layer(extract_1_2)\n",
    "# extract_2_2 = shared_LSTM_layer2(dropped_1_2)\n",
    "# dropped_2_2 = shared_dropout_layer(extract_2_2)\n",
    "# dense_1_2 = shared_dense_layer(dropped_2_2)\n",
    "# dense_2_2 = shared_dense_layer_2(dense_1_2)\n",
    "\n",
    "\n",
    "# # Third input\n",
    "# visible_1_3 = Input(shape=(timesteps,features))\n",
    "# extract_1_3 = shared_LSTM_layer(visible_1_3)\n",
    "# dropped_1_3 = shared_dropout_layer(extract_1_3)\n",
    "# extract_2_3 = shared_LSTM_layer2(dropped_1_3)\n",
    "# dropped_2_3 = shared_dropout_layer(extract_2_3)\n",
    "# dense_1_3 = shared_dense_layer(dropped_2_3)\n",
    "# dense_2_3 = shared_dense_layer_2(dense_1_3)\n",
    "\n",
    "# # merge(\n",
    "# #         [positive_item_embedding, negative_item_embedding, user_embedding],\n",
    "# #         mode=bpr_triplet_loss,\n",
    "# #         name='loss',\n",
    "# #         output_shape=(1, ))\n",
    "# output = merge([visible_1,visible_1_2,visible_1_3],mode=standard_triplet_loss,output_shape=(1,))\n",
    "# model = Model(inputs=[visible_1, visible_1_2,visible_1_3], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=identity_loss, optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "Run for a couple of epochs, checking the AUC after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "Epoch 100\n",
      "Epoch 150\n",
      "Epoch 200\n",
      "Epoch 250\n",
      "Epoch 300\n",
      "Epoch 350\n",
      "Epoch 400\n",
      "Epoch 450\n",
      "Epoch 500\n",
      "Epoch 550\n",
      "Epoch 600\n",
      "Epoch 650\n",
      "Epoch 700\n",
      "Epoch 750\n",
      "Epoch 800\n",
      "Epoch 850\n",
      "Epoch 900\n",
      "Epoch 950\n",
      "Epoch 1000\n",
      "Epoch 1050\n",
      "Epoch 1100\n",
      "Epoch 1150\n",
      "Epoch 1200\n",
      "Epoch 1250\n",
      "Epoch 1300\n",
      "Epoch 1350\n",
      "Epoch 1400\n",
      "Epoch 1450\n",
      "Epoch 1500\n",
      "Epoch 1550\n",
      "Epoch 1600\n",
      "Epoch 1650\n",
      "Epoch 1700\n",
      "Epoch 1750\n",
      "Epoch 1800\n",
      "Epoch 1850\n",
      "Epoch 1900\n",
      "Epoch 1950\n",
      "Epoch 2000\n",
      "Epoch 2050\n",
      "Epoch 2100\n",
      "Epoch 2150\n",
      "Epoch 2200\n",
      "Epoch 2250\n",
      "Epoch 2300\n",
      "Epoch 2350\n",
      "Epoch 2400\n",
      "Epoch 2450\n",
      "Epoch 2500\n",
      "Epoch 2550\n",
      "Epoch 2600\n",
      "Epoch 2650\n",
      "Epoch 2700\n",
      "Epoch 2750\n",
      "Epoch 2800\n",
      "Epoch 2850\n",
      "Epoch 2900\n",
      "Epoch 2950\n",
      "Epoch 3000\n",
      "Epoch 3050\n",
      "Epoch 3100\n",
      "Epoch 3150\n",
      "Epoch 3200\n",
      "Epoch 3250\n",
      "Epoch 3300\n",
      "Epoch 3350\n",
      "Epoch 3400\n",
      "Epoch 3450\n",
      "Epoch 3500\n",
      "Epoch 3550\n",
      "Epoch 3600\n",
      "Epoch 3650\n",
      "Epoch 3700\n",
      "Epoch 3750\n",
      "Epoch 3800\n",
      "Epoch 3850\n",
      "Epoch 3900\n",
      "Epoch 3950\n",
      "Epoch 4000\n",
      "Epoch 4050\n",
      "Epoch 4100\n",
      "Epoch 4150\n",
      "Epoch 4200\n",
      "Epoch 4250\n",
      "Epoch 4300\n",
      "Epoch 4350\n",
      "Epoch 4400\n",
      "Epoch 4450\n",
      "Epoch 4500\n",
      "Epoch 4550\n",
      "Epoch 4600\n",
      "Epoch 4650\n",
      "Epoch 4700\n",
      "Epoch 4750\n",
      "Epoch 4800\n",
      "Epoch 4850\n",
      "Epoch 4900\n",
      "Epoch 4950\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    if epoch % 50 == 0:\n",
    "        print('Epoch %s' % epoch)\n",
    "    \n",
    "    # Sample triplets from the training data\n",
    "    first_data, second_data, random_data,uris = get_train_batch(BATCH_SIZE,vector_size,unique_uris)\n",
    "    X = [first_data,second_data,random_data]\n",
    "    model.fit(X,\n",
    "              np.ones(len(first_data)),\n",
    "              batch_size=BATCH_SIZE,\n",
    "              nb_epoch=1,\n",
    "              verbose=0,\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = '/Users/spandanmadan/Desktop/Spotify/Spotify/data/pooling/saved_lstm_5000.h5'\n",
    "model.save(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get embeddings from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uri_to_input_vector(uris):\n",
    "    data = np.zeros((BATCH_SIZE,vector_size))\n",
    "    for uri in uris:\n",
    "        data[i] = vectorizer.transform(uri_to_lyrics[uri]).toarray()\n",
    "    reshaped_data = data.reshape((BATCH_SIZE,timesteps,-1))\n",
    "    return reshaped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-bf89c41402a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mextract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_LSTM_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_dropout_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mextract_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_LSTM_layer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdrop_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_dropout_layer_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   2110\u001b[0m                                       \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m                                       \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m                                       initial_state=initial_state)\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    607\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2769\u001b[0m             \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m             \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2771\u001b[0;31m             swap_memory=True)\n\u001b[0m\u001b[1;32m   2772\u001b[0m         \u001b[0mlast_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m         \u001b[0moutput_ta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\u001b[0m\n\u001b[1;32m   3222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3224\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2956\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2957\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2891\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   2892\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   2752\u001b[0m                     \u001b[0mTuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m                 \"\"\"\n\u001b[0;32m-> 2754\u001b[0;31m                 \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2755\u001b[0m                 output, new_states = step_function(current_input,\n\u001b[1;32m   2756\u001b[0m                                                    \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0moverride_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0moverride_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0moverride_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, index, name)\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mat\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     \"\"\"\n\u001b[0;32m--> 861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_should_use\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_use_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, index, name)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mflow_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\u001b[0m in \u001b[0;36mtensor_array_read_v3\u001b[0;34m(handle, index, flow_in, dtype, name)\u001b[0m\n\u001b[1;32m   6426\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   6427\u001b[0m         \u001b[0;34m\"TensorArrayReadV3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflow_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6428\u001b[0;31m         dtype=dtype, name=name)\n\u001b[0m\u001b[1;32m   6429\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6430\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1760\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1769\u001b[0m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1771\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1772\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recompute_node_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddOp\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0mop_input_ctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2445\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_AddOpInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_AddOpInternal\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   2464\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2466\u001b[0;31m         \u001b[0mreal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2467\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreal_x\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_x\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddValue\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m   2408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m             \u001b[0mis_constant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m             parallel_iterations=self._parallel_iterations)\n\u001b[0m\u001b[1;32m   2411\u001b[0m         \u001b[0menter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevent_feeding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outer_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_Enter\u001b[0;34m(data, frame_name, is_constant, parallel_iterations, use_ref, use_input_shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m       result = gen_control_flow_ops.enter(\n\u001b[0;32m--> 271\u001b[0;31m           data, frame_name, is_constant, parallel_iterations, name=name)\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/gen_control_flow_ops.py\u001b[0m in \u001b[0;36menter\u001b[0;34m(data, frame_name, is_constant, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    176\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m    177\u001b[0m         \u001b[0;34m\"Enter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_constant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_constant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         parallel_iterations=parallel_iterations, name=name)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "visible = Input(shape=(timesteps,features))\n",
    "extract = shared_LSTM_layer(visible)\n",
    "drop = shared_dropout_layer(extract)\n",
    "extract_ = shared_LSTM_layer2(drop)\n",
    "drop_ = shared_dropout_layer_2(extract_)\n",
    "flat = shared_flatten(drop_)\n",
    "dense = shared_dense_layer(flat)\n",
    "dense_ = shared_dense_layer_2(dense)\n",
    "\n",
    "# model = Model(inputs=[visible_1, visible_1_2,visible_1_3], outputs=output)\n",
    "prediction_model = Model(inputs=visible,outputs=dense_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = '/Users/spandanmadan/Desktop/Spotify/Spotify/data/pooling/saved_prediction_model_5000.h5'\n",
    "prediction_model.save(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_model = Sequential()\n",
    "# prediction_model.add(LSTM(700,return_sequences=True,\n",
    "#                input_shape=(timesteps, features),weights=shared_LSTM_layer.get_weights()))  # returns a sequence of vectors of dimension 32\n",
    "# prediction_model.add(Dropout(0.5))\n",
    "# prediction_model.add(LSTM(500, return_sequences=True,weights=shared_LSTM_layer2.get_weights()))  # returns a sequence of vectors of dimension 32\n",
    "# prediction_model.add(Dropout(0.5))\n",
    "# prediction_model.add(Dense(500, activation='relu',weights=shared_dense_layer.get_weights()))\n",
    "# prediction_model.add(Dense(300, activation='relu',weights=shared_dense_layer_2.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(prediction_model,to_file='prediction_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 11, 129)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 11, 700)           2324000   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 11, 700)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 11, 500)           2402000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 11, 500)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 5500)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              5501000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               300300    \n",
      "=================================================================\n",
      "Total params: 10,527,300\n",
      "Trainable params: 10,527,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prediction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 11, 129)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 11, 129)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 11, 129)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 11, 700)      2324000     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 11, 700)      0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "                                                                 lstm_3[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 11, 500)      2402000     dropout_3[0][0]                  \n",
      "                                                                 dropout_3[1][0]                  \n",
      "                                                                 dropout_3[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 11, 500)      0           lstm_4[0][0]                     \n",
      "                                                                 lstm_4[1][0]                     \n",
      "                                                                 lstm_4[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 5500)         0           dropout_4[0][0]                  \n",
      "                                                                 dropout_4[1][0]                  \n",
      "                                                                 dropout_4[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1000)         5501000     flatten_5[0][0]                  \n",
      "                                                                 flatten_5[1][0]                  \n",
      "                                                                 flatten_5[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 300)          300300      dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "                                                                 dense_3[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 1)            0           dense_4[0][0]                    \n",
      "                                                                 dense_4[1][0]                    \n",
      "                                                                 dense_4[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,527,300\n",
      "Trainable params: 10,527,300\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "prediction_model = load_model('../data/pooling/saved_prediction_model_5000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_to_embeding = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108093"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(all_uris),5):\n",
    "    uris = all_uris[i:i+5]\n",
    "    if len(uris) < 5:\n",
    "        rem = 5 - len(uris)\n",
    "        for  j in len(rem):\n",
    "            uris.append(all_uris[0])\n",
    "    input_data = np.zeros((BATCH_SIZE,vector_size))\n",
    "    \n",
    "    for k in range(len(uris)):\n",
    "        input_data[k] = vectorizer.transform(uri_to_lyrics[uris[k]]).toarray()\n",
    "        reshaped_data = input_data.reshape((BATCH_SIZE,timesteps,-1))\n",
    "        prediction = prediction_model.predict(reshaped_data)\n",
    "        uri_to_embeding[uris[k]] = prediction\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0UaMYEvWZi0ZqiDOoHU3YI', '6I9VzXrHxO9rA9A5euc8Ak', '0WqIKmW4BTrj3eJFmnCKMv', '1AWQoqb9bSvzTjaLralEkT', '1lzr43nnXAijIGYnCT8M8H'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri_to_embeding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 11, 129)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, 0.2, 0.2], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(uri_to_embeding['6I9VzXrHxO9rA9A5euc8Ak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_songs(uri_list):\n",
    "    for uri in uri_list:\n",
    "        print(uri_to_name_artist['spotify:track:'+uri])\n",
    "\n",
    "def compare_outputs(activations_first,activations_second,activations_random):\n",
    "    mean_1 = np.mean(activations_first,axis=0)\n",
    "    mean_2 = np.mean(activations_second,axis=0)\n",
    "    mean_random = np.mean(activations_random,axis=0)\n",
    "    \n",
    "    A = np.linalg.norm(mean_1 - mean_2,2)\n",
    "    B = np.linalg.norm(mean_1 - mean_random,2)\n",
    "    \n",
    "    return A,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = get_train_batch(BATCH_SIZE,vector_size,unique_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_first = prediction_model.predict(a)\n",
    "activations_second = prediction_model.predict(b)\n",
    "activations_random = prediction_model.predict(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/spandanmadan/Desktop/Spotify/Spotify/data/pooling/uri_to_name_artist.p','rb')\n",
    "uri_to_name_artist = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First songs-\n",
      "('An Anthem of Invitation', 'Judah & the Lion')\n",
      "('Shepherd of My Soul', 'Rivers & Robots')\n",
      "('Fall Down', 'Rivers & Robots')\n",
      "('I Surrender All', 'Ascend The Hill')\n",
      "('Oh Love That Will Not Let Me Go', 'Ascend The Hill')\n",
      "Second songs-\n",
      "('Voice That Stills the Raging Sea', 'Rivers & Robots')\n",
      "('Light Will Dawn', 'Rivers & Robots')\n",
      "('See the Way (feat. David Brymer)', 'Misty Edwards')\n",
      "('Shepherd of My Soul', 'Rivers & Robots')\n",
      "('Farther Along', 'Josh Garrels')\n",
      "Third songs-\n",
      "('Everybody Wants to Go to Heaven', 'Kenny Chesney')\n",
      "('All I Ask Of You (feat. Pennybirdrabbit) - feat. Penny', 'Skrillex')\n",
      "('Jorge Regula', 'The Moldy Peaches')\n",
      "('Dawn of Time', 'Tribal Seeds')\n",
      "('Never Too Far Gone', 'Jordan Feliz')\n"
     ]
    }
   ],
   "source": [
    "print('First songs-')\n",
    "print_songs(d[0])\n",
    "print('Second songs-')\n",
    "print_songs(d[1])\n",
    "print('Third songs-')\n",
    "print_songs(d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.009273529, 0.016392708)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_outputs(activations_first,activations_second,activations_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
